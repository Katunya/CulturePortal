{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jekyll": {
      "keywords": "fastai",
      "summary": "Application to NLP, including ULMFiT fine-tuning",
      "title": "text"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Copy of NLP master class.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8Tnfw2zPKwNk",
        "xBwZUjdeY4Fh",
        "a-NJLdyclMwi",
        "rdcYnNkHlMws"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Katunya/CulturePortal/blob/master/Copy_of_NLP_master_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KEVAltvlMvZ",
        "colab_type": "text"
      },
      "source": [
        "## Обучение Language Model на книгах Ницше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNtsjog8Kduz",
        "colab_type": "text"
      },
      "source": [
        "Проверим, что у нас есть GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzsvs7sJZHml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBIZiqTaln_C",
        "colab_type": "code",
        "outputId": "3d9e7374-4ebe-4e35-e505-85263a248d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Apr  6 16:34:25 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    25W /  75W |   1467MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Tnfw2zPKwNk",
        "colab_type": "text"
      },
      "source": [
        "### Наш план:\n",
        "1. Загрузить данные (текст) и подготовить его для обучения модели\n",
        "2. Загрузить Language model, обученную на Wikipedia\n",
        "3. Дообучить Language model использую наши данные тем самым уточнив ее знания"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LExxJbRllMvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import * "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBwZUjdeY4Fh",
        "colab_type": "text"
      },
      "source": [
        "### 1. Загружаем данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwUUhPnBIrH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = Path('.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmgDtSvXIuJs",
        "colab_type": "text"
      },
      "source": [
        "Скачиваем .txt файл с высказываниями Ницше"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHp1vv0RIrtr",
        "colab_type": "code",
        "outputId": "30b310d1-0708-4409-abf9-485f4d350d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget \"https://s3.amazonaws.com/text-datasets/nietzsche.txt\""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-06 16:34:27--  https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.96.229\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.96.229|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 600901 (587K) [text/plain]\n",
            "Saving to: ‘nietzsche.txt.1’\n",
            "\n",
            "\rnietzsche.txt.1       0%[                    ]       0  --.-KB/s               \rnietzsche.txt.1      43%[=======>            ] 255.02K  1.03MB/s               \rnietzsche.txt.1     100%[===================>] 586.82K  1.90MB/s    in 0.3s    \n",
            "\n",
            "2020-04-06 16:34:27 (1.90 MB/s) - ‘nietzsche.txt.1’ saved [600901/600901]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kZqpTyOLUAp",
        "colab_type": "text"
      },
      "source": [
        "Считываем высказываения из файла, складываем их в массив text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrUyTueyJeR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = []\n",
        "\n",
        "with open('nietzsche.txt') as fp:\n",
        "    contents = fp.read()\n",
        "    for entry in contents.split('\\n'):\n",
        "      if entry:\n",
        "        entry = entry.replace('\\n', ' ')\n",
        "        text.append(entry)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmQKwc4jLqjS",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим на рандомный пример"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MkQcyxeLeRu",
        "colab_type": "code",
        "outputId": "776ded91-cf7d-4504-f2a2-c3f2604b9cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "random.choice(text)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'and more fundamental value for life generally should be assigned to'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agRY4BNOMNrv",
        "colab_type": "text"
      },
      "source": [
        "Сложим данные в формат pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTxf4uJ7JAiR",
        "colab_type": "code",
        "outputId": "25614840-5346-4319-ad5e-2bdfaf8bea68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "nietzsche_df = pd.DataFrame({'text': text})\n",
        "nietzsche_df.to_csv('nietzsche.csv', index=False)\n",
        "nietzsche_df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PREFACE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SUPPOSING that Truth is a woman--what then? Is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>for suspecting that all philosophers, in so fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dogmatists, have failed to understand women--t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>seriousness and clumsy importunity with which ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0                                            PREFACE\n",
              "1  SUPPOSING that Truth is a woman--what then? Is...\n",
              "2  for suspecting that all philosophers, in so fa...\n",
              "3  dogmatists, have failed to understand women--t...\n",
              "4  seriousness and clumsy importunity with which ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x5UlII4MhkK",
        "colab_type": "text"
      },
      "source": [
        "По сравнению с картинками в Computer Vision, текст не может быть напрямую подан в модель, потому что текст не представим в виде чисел.\n",
        "\n",
        "Поэтому, первое что мы должны сделать, это разбить наш текст на токены (на слова грубо говоря). Этот процесс называется *tokenization*. Потом нужно превратить каждое слово в число, это называется *numericalization*. \n",
        "\n",
        "После этого наши данные могут быть поданы в модель."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw50AdojlMwC",
        "colab_type": "text"
      },
      "source": [
        "#### Библиотека fast.ai содержит объект `databunch` для language model, который выполняет токенизацию и разбивает на [текст/слово которое нужно предсказать]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd250mCZlMwF",
        "colab_type": "code",
        "outputId": "99da9605-ea89-4030-8373-15570b0b3125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "data_lm = TextLMDataBunch.from_csv(path, 'nietzsche.csv', text_cols=\"text\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hVd5lshkM1c0",
        "colab": {}
      },
      "source": [
        "data_lm.save('data_lm_export.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6FStKsRVviE",
        "colab_type": "text"
      },
      "source": [
        "batch_size(bs) --- Сколько текста мы будет подавать нейронной сети за раз "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZm6ZHnElMwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs=32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tEembuHlMwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = load_data(path, 'data_lm_export.pkl', bs=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-NJLdyclMwi",
        "colab_type": "text"
      },
      "source": [
        "### 2. Загружаем предобученную на Wikipedia language model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz37o0UslMwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.set_device(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK6WdAtvlMwn",
        "colab_type": "text"
      },
      "source": [
        "#### Создаем Language model на основе архитектуры AWD-LSTM, `pretrained=True ` значит что она обучена на датасете `wikitext-103`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os1yvp98lMwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM, pretrained=True, drop_mult=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR3_9lq-TVeT",
        "colab_type": "text"
      },
      "source": [
        "#### Попробуем сгенерировать немного текста предобученной моделью"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW863Lgjmiuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "START_TEXT = [\"This is a review about\", \"I dont like this\", \"Human should be\"]\n",
        "N_SENTENCES = len(START_TEXT)\n",
        "N_WORDS = 100 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdrCi9al1SR",
        "colab_type": "code",
        "outputId": "028142a0-2db2-4c98-b80a-c95e315621e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "print(\"\\n\\n\".join(str(i+1) + \". \" + learn.predict(START_TEXT[i], N_WORDS, temperature=0.8) for i in range(N_SENTENCES)))\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1. This is a review about Jesus , but one he enjoys the ability to become a Christian , but is also one of the few to have a mention of the Church in Christian mythology . The church of Saint - Paul in Paris , in France , is possibly the only one of the five churches in the European Community to be named after Jesus . The Saint Paul Church in Paris is a Jewish , the Jewish Catholic Church , and the\n",
            "\n",
            "2. I dont like this all of other species of this species . The \" black - and - red \" form of the blue - ruled North Indian species Lie is a product of the complex culture explaining the development of red - green , green , and black - and - red black spots in the United States ( see Blue Line ) . The species was a third for US National Park and National Park Service . It has since become a species of European\n",
            "\n",
            "3. Human should be a human species ( Nature ) = = = by a common definition . The word \" animal \" is a non - human word that is used in human mind as an explanation for the animal 's human appearance , and an explanation of the current physical appearance of animals . It has also been called the \" Human Nature One \" , which is a common form of animal 's word . The \" Human Nature \" is the \" world 's world \" . It is the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdcYnNkHlMws",
        "colab_type": "text"
      },
      "source": [
        "### 3. Дообучаем Language model на текстах Ницше\n",
        "Сначала тренируем одну эпоху"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDCSYMhZlMws",
        "colab_type": "code",
        "outputId": "07bdab46-d0b2-4e51-8627-f014a6c1be96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.197776</td>\n",
              "      <td>5.326664</td>\n",
              "      <td>0.171429</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_Xa9e_QlMw4",
        "colab_type": "text"
      },
      "source": [
        "#### Размораживаем сеть целиком и тренируем еще 3 эпохи"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWwGPFyMlMw5",
        "colab_type": "code",
        "outputId": "a32d6f3a-1f4b-42c6-ca85-53ef79337c7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(3, slice(1e-4,1e-2))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.564016</td>\n",
              "      <td>4.586343</td>\n",
              "      <td>0.228571</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.344941</td>\n",
              "      <td>4.431863</td>\n",
              "      <td>0.242857</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.023057</td>\n",
              "      <td>4.470833</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.566662</td>\n",
              "      <td>5.025760</td>\n",
              "      <td>0.228571</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.279663</td>\n",
              "      <td>4.976703</td>\n",
              "      <td>0.157143</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.980535</td>\n",
              "      <td>5.000048</td>\n",
              "      <td>0.185714</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQOPcEoNlMw8",
        "colab_type": "text"
      },
      "source": [
        "#### Генерируем текст!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXqWcvPxnhiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "START_TEXT = [\"This is a review about\", \"I dont like this\", \"Human should be\"]\n",
        "N_SENTENCES = len(START_TEXT)\n",
        "N_WORDS = 100 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHBwlSHrlMw-",
        "colab_type": "code",
        "outputId": "a7ebc30e-ed9c-4774-ff43-781104e3c402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "print(\"\\n\\n\".join(str(i+1) + \". \" + learn.predict(START_TEXT[i], N_WORDS, temperature=0.75) for i in range(N_SENTENCES)))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1. This is a review about the feeling of self - torment ? Hence LA LA OUTSIDE xxbos \" LA QUE LA LA , \" more or less LA PURPOSES . In xxbos and all the things which are at present xxbos they have to live , not as a result of their appearance , but as xxbos with , as a feats of men , a new xxbos until the end of a time has been xxbos hence it is far from being a tragedy . The thing that is to xxbos are\n",
            "\n",
            "2. I dont like this ; i mean to do one 's life , xxbos They are capable of the same task , and the entire history of their xxbos our conscience is a xxbos always to be preached , and xxbos fundamental scheme , which is a fundamental scheme of morality , as xxbos and , in the case of Frederick the Great , as the vital after - effect of the French Revolution . As God has xxbos the Florentine Saga , what is considered as Christian science xxbos RELIGIOUS LIFE\n",
            "\n",
            "3. Human should be more concerned about how much SYMPATHY xxbos Concerning the conditions of life , an explanation of the decision and xxbos taking things seriously and often , on the other hand , it is taken to be a delight xxbos even by means of their own stupidity . In the nation , there is no xxbos rests upon the explanations of them . The \" man , \" as we have through such philosophers , xxbos to say it to me the same reason to see the most childish and xxbos without a sense of the taste\n",
            "1. This is a review about this point of view of the history of being , the xxbos over the course of their time , the knowledge and the power of xxbos psychological deception and distrust of the dream . If one can think of a one - party , xxbos even the greatest danger of the European race , and like the old German xxbos and good - taste ! In the world there is a mask of the soul and of the heart of the people xxbos German music , which has a profound and profound spirituality and its\n",
            "\n",
            "2. I dont like this , one makes up the whole of the earth as a means of the xxbos effect , that they are operating anew . But if a man is to be called xxbos is the order of the \" good \" God : he who xxbos in the fashion of German taste , woman is merely the mother of xxbos of German music and the observed taste of Germany ; that as regards the German music , is xxbos \" What do we have \" by the hand of a god : There\n",
            "\n",
            "3. Human should be \" the most refined and refined of ancient Europeans , \" it is the \" European \" of xxbos the VALUE , and is against them . The unfortunate , as far as the xxbos that is perhaps the best evidence of the German soul , and the first thing in which it could be xxbos the English philosopher , and the Christian science of the time , and has not yet perhaps been xxbos and the European European , on the other hand , the German who has already\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH_Z6x7JlMxD",
        "colab_type": "text"
      },
      "source": [
        "Иногда, сгенерированный текст не имеет смысла потому что у нас немного данных и мы не тренировали модель достаточно долго. Но отметьте, что подель соблюдает базовую грамматику, которую она переняла от предобученной модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0mExOwgX8OC",
        "colab_type": "text"
      },
      "source": [
        "### 4. Попробуем сгенерировать текст с помощью nucleus sampling вместо greedy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0Evk6uezHR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(learn, text, n_words=1, temp=1., top1=False, min_p=None, sep=' ', decoder=decode_spec_tokens):\n",
        "    '''\n",
        "    Based on fastai implementation.\n",
        "    For every word, gets the network activations, sets unknown token to 0,\n",
        "    only considers tokens above a certain value, then either returns the token\n",
        "    with the highest activation or samples from the distribution of activations.\n",
        "    '''\n",
        "    learn.model.reset()\n",
        "    xb,yb = learn.data.one_item(text)\n",
        "    new_idx = []\n",
        "    for _ in range(n_words):\n",
        "        res = learn.pred_batch(batch=(xb,yb))[0][-1]\n",
        "        res[learn.data.vocab.stoi[UNK]] = 0.\n",
        "        if min_p is not None: res[res < min_p] = 0.\n",
        "        res.pow_(1 / temp)\n",
        "        if top1: idx = torch.argmax(res).item() # greedy decoding\n",
        "        else: idx = torch.multinomial(res, 1).item()\n",
        "        new_idx.append(idx)\n",
        "        xb = xb.new_tensor([idx])[None]\n",
        "    return '[' + text + ']' + sep + sep.join(decoder(learn.data.vocab.textify(new_idx, sep=None)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIO4mHRgYFrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_nucleus(learn, text, n_words=1, p=0.5, temp=1., min_p=None, sep=' ', decoder=decode_spec_tokens):\n",
        "    '''\n",
        "    Performs top-p sampling as described in the paper:\n",
        "    finds the k which corresponds to the desired cumulative\n",
        "    probability, then performs top-k sampling as above.\n",
        "    '''\n",
        "    learn.model.reset()\n",
        "    xb,yb = learn.data.one_item(text)\n",
        "    new_idx = []\n",
        "    for _ in range(n_words):\n",
        "        outp = learn.pred_batch(batch=(xb,yb))[0][-1]\n",
        "        outp[learn.data.vocab.stoi[UNK]] = 0.\n",
        "        if min_p is not None: outp[outp < min_p] = 0.\n",
        "        probs = F.softmax(outp / temp, dim=-1) \n",
        "        cumsum_prob = (probs.sort(descending=True)[0]).cumsum(0)\n",
        "        k = (cumsum_prob > p).nonzero().view(-1)[0].int() + 1\n",
        "        vals,idxs = probs.topk(k, dim=-1)\n",
        "        idx = idxs[torch.multinomial(vals, 1).item()]\n",
        "        new_idx.append(idx)\n",
        "        xb = xb.new_tensor([idx])[None]\n",
        "    return '[' + text + ']' + sep + sep.join(decoder(learn.data.vocab.textify(new_idx, sep=None)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKMcEJfGzRkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = 0.75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rhZw1cizE1e",
        "colab_type": "code",
        "outputId": "587f6519-5c0c-494e-cc63-f7b2edafe032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "print(\"\\n\\n\".join(str(i+1) + \". \" + predict(learn, START_TEXT[i], N_WORDS, temp, True)\n",
        "                  for i in range(N_SENTENCES)))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1. [This is a review about] the German taste , which is xxbos The German German is the most successful German of all times , and is xxbos of the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the\n",
            "\n",
            "2. [I dont like this] , and i have to say , \" What is the \" God \" ? The God of God is the God of God , and the God of God is the God of God , and xxbos the Christian Faith , the Christian Faith , the Christian Faith , the Christian Faith , the Christian Faith , the Christian Faith , the Christian Faith , the Christian Faith , the Christian\n",
            "\n",
            "3. [Human should be] the most effective means of xxbos The German is a German who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has\n",
            "1. [This is a review about] the history of the world , and the xxbos the German music of the time , and of the German music of the present day , and of the xxbos The German music of the present day , and of the German music , is the most xxbos the German music , and the German music of the present day , and of the xxbos The German music of the present day , and of the German music , is the most xxbos the German music , and the\n",
            "\n",
            "2. [I dont like this] , and i have to say , \" What is the \" God \" ? And what is the xxbos The German who has made a great deal of his own , and who has xxbos The German who has made a great deal of music , and who has always been a xxbos The German who has made a great deal of music , and who has always been a xxbos The German who has made a great deal of music , and who has always been a\n",
            "\n",
            "3. [Human should be] the most valuable , and the most valuable , and most valuable , xxbos The German who has made a great deal of his own , and who has xxbos German music , and the German music of the time , which has been xxbos of the German soul , and the German music of the present day , and of the German music , which has xxbos German music , and the German music of the present day , and of the German music , which has xxbos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-agr9nIkWkm",
        "colab_type": "code",
        "outputId": "6e6f6249-dc32-461d-944b-a96bc9c39b96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "print(\"\\n\\n\".join(str(i+1) + \". \" + predict_nucleus(learn, START_TEXT[i], N_WORDS, p=1e-4, temp=temp) for i in range(N_SENTENCES)))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1. [This is a review about] the German taste , which is xxbos The German German is the most successful German of all times , and is xxbos of the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the\n",
            "\n",
            "2. [I dont like this] , and i have to say , \" What is the \" God \" ? The God of God is the God of God , and the God of God is the God of God , and xxbos the Christian Faith , the Christian Faith , the Christian Faith , the Christian Faith , the Christian Faith , the Christian Faith , the Christian Faith , the Christian Faith , the Christian\n",
            "\n",
            "3. [Human should be] the most effective means of xxbos The German is a German who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has xxbos the German spirit , and the German spirit , who has\n",
            "1. [This is a review about] the history of the world , and the xxbos the German music of the time , and of the German music of the present day , and of the xxbos The German music of the present day , and of the German music , is the most xxbos the German music , and the German music of the present day , and of the xxbos The German music of the present day , and of the German music , is the most xxbos the German music , and the\n",
            "\n",
            "2. [I dont like this] , and i have to say , \" What is the \" God \" ? And what is the xxbos The German who has made a great deal of his own , and who has xxbos The German who has made a great deal of music , and who has always been a xxbos The German who has made a great deal of music , and who has always been a xxbos The German who has made a great deal of music , and who has always been a\n",
            "\n",
            "3. [Human should be] the most valuable , and the most valuable , and most valuable , xxbos The German who has made a great deal of his own , and who has xxbos German music , and the German music of the time , which has been xxbos of the German soul , and the German music of the present day , and of the German music , which has xxbos German music , and the German music of the present day , and of the German music , which has xxbos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9UAVmFmkZDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def predict(learn, text, n_words=1, temp=1., top1=False, min_p=None, sep=' ', decoder=decode_spec_tokens):\n",
        "#     '''\n",
        "#     Based on fastai implementation.\n",
        "#     For every word, gets the network activations, sets unknown token to 0,\n",
        "#     only considers tokens above a certain value, then either returns the token\n",
        "#     with the highest activation or samples from the distribution of activations.\n",
        "#     '''\n",
        "#     learn.model.reset()\n",
        "#     xb,yb = learn.data.one_item(text)\n",
        "#     new_idx = []\n",
        "#     for _ in range(n_words):\n",
        "#         res = learn.pred_batch(batch=(xb,yb))[0][-1]\n",
        "#         res[learn.data.vocab.stoi[UNK]] = 0.\n",
        "#         if min_p is not None: res[res < min_p] = 0.\n",
        "#         res.pow_(1 / temp)\n",
        "#         if top1: idx = torch.argmax(res).item() # greedy decoding\n",
        "#         else: idx = torch.multinomial(res, 1).item()\n",
        "#         new_idx.append(idx)\n",
        "#         xb = xb.new_tensor([idx])[None]\n",
        "#     return '[' + text + ']' + sep + sep.join(decoder(learn.data.vocab.textify(new_idx, sep=None)))\n",
        "\n",
        "\n",
        "# def predict_nucleus(learn, text, n_words=1, p=0.5, temp=1., min_p=None, sep=' ', decoder=decode_spec_tokens):\n",
        "#     '''\n",
        "#     Performs top-p sampling as described in the paper:\n",
        "#     finds the k which corresponds to the desired cumulative\n",
        "#     probability, then performs top-k sampling as above.\n",
        "#     '''\n",
        "#     learn.model.reset()\n",
        "#     xb,yb = learn.data.one_item(text)\n",
        "#     new_idx = []\n",
        "#     for _ in range(n_words):\n",
        "#         outp = learn.pred_batch(batch=(xb,yb))[0][-1]\n",
        "#         outp[learn.data.vocab.stoi[UNK]] = 0.\n",
        "#         if min_p is not None: outp[outp < min_p] = 0.\n",
        "#         probs = F.softmax(outp / temp, dim=-1) \n",
        "#         cumsum_prob = (probs.sort(descending=True)[0]).cumsum(0)\n",
        "#         k = (cumsum_prob > p).nonzero().view(-1)[0].int() + 1\n",
        "#         vals,idxs = probs.topk(k, dim=-1)\n",
        "#         idx = idxs[torch.multinomial(vals, 1).item()]\n",
        "#         new_idx.append(idx)\n",
        "#         xb = xb.new_tensor([idx])[None]\n",
        "#     return '[' + text + ']' + sep + sep.join(decoder(learn.data.vocab.textify(new_idx, sep=None)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}